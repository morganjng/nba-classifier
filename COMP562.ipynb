{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Statistic Predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hLbjgX09Oa40"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ttn-Z0s0W0Ai"
   },
   "source": [
    "## Abbreviation key\n",
    "| Name | Description |\n",
    "| :-- | :----: |\n",
    "| gp | games played\n",
    "| net_rating | offRating - defRating\n",
    "| offRating | 100*((points)/POSS)\n",
    "| defRating | 100*((opp points/(opp POSS)))\n",
    "| oreb_pct | offensive rebound percentage\n",
    "| usg_pct | percentage of team plays utilized by a player while they are in the game\n",
    "| ts_pct | true shooting percentage;  percentage of shots made factoring in threes and free throws.  \n",
    "| ast_ptg | assist percentage; percent of field goals (2 or 3 point shots not including free throws) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g07GetHTUoXW",
    "outputId": "629c1d17-7b99-4952-d458-3bdbd622e7e5"
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/morganjng/nba-classifier/blob/main/all_seasons.csv\n",
    "csv = pd.read_csv(\"all_seasons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HggkbrXVPrQ",
    "outputId": "afc6e8b4-6abc-414f-ee33-ab53851e50a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'player_name', 'team_abbreviation', 'age',\n",
      "       'player_height', 'player_weight', 'college', 'country', 'draft_year',\n",
      "       'draft_round', 'draft_number', 'gp', 'pts', 'reb', 'ast', 'net_rating',\n",
      "       'oreb_pct', 'dreb_pct', 'usg_pct', 'ts_pct', 'ast_pct', 'season'],\n",
      "      dtype='object') 11700\n"
     ]
    }
   ],
   "source": [
    "total_players = len(csv[\"player_name\"])\n",
    "print(csv.columns, total_players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processsing the dataset\n",
    "### Building a function to return one-hot vectors for string entries in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcbTc_xTnL3M",
    "outputId": "f7da51dc-b84f-41e8-e61e-e61ae88881a2"
   },
   "outputs": [],
   "source": [
    "colleges = []\n",
    "countries = []\n",
    "years = []\n",
    "seasons = []\n",
    "teams = []\n",
    "for i in range(0, total_players):\n",
    "    if(csv[\"college\"][i] not in colleges):\n",
    "        colleges.append(csv[\"college\"][i])\n",
    "    if(csv[\"country\"][i] not in countries):\n",
    "        countries.append(csv[\"country\"][i])\n",
    "    if(csv[\"draft_year\"][i] not in colleges):\n",
    "        years.append(csv[\"draft_year\"][i])\n",
    "    if(csv[\"season\"][i] not in seasons):\n",
    "        seasons.append(csv[\"season\"][i])\n",
    "    if(csv[\"team_abbreviation\"][i] not in teams):\n",
    "        teams.append(csv[\"team_abbreviation\"][i])\n",
    "# print(colleges, countries, years, seasons, teams)\n",
    "\n",
    "def one_hot(value, array):\n",
    "    v = [0 for i in range(len(array))]\n",
    "    v[array.index(value)] = 1\n",
    "    return torch.Tensor(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling n/a entries in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvnWL8J0yCJq",
    "outputId": "9ace3917-5648-4a74-f410-2d492979233e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3737/2124559815.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csv[\"draft_number\"][i] = mean_number\n",
      "/tmp/ipykernel_3737/2124559815.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csv[\"draft_round\"][i] = mean_round\n"
     ]
    }
   ],
   "source": [
    "sum_round = 0\n",
    "count_round = 0\n",
    "sum_number = 0\n",
    "count_number = 0\n",
    "for i in range(0, total_players):\n",
    "    if(csv[\"draft_number\"][i] != \"Undrafted\"):\n",
    "        sum_number += int(csv[\"draft_number\"][i])\n",
    "        count_number += 1\n",
    "    if(csv[\"draft_round\"][i] != \"Undrafted\"):\n",
    "        sum_round += int(csv[\"draft_round\"][i])\n",
    "        count_round += 1\n",
    "\n",
    "mean_round = sum_round / count_round\n",
    "mean_number = sum_number / count_number\n",
    "print(mean_round, mean_number)\n",
    "\n",
    "for i in range(0, total_players):\n",
    "    if(csv[\"draft_number\"][i] == \"Undrafted\"):\n",
    "        csv[\"draft_number\"][i] = mean_number\n",
    "    if(csv[\"draft_round\"][i] == \"Undrafted\"):\n",
    "        csv[\"draft_round\"][i] = mean_round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB2uQ3dqZBfV"
   },
   "source": [
    "### Defining a function to split up our data randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "EcBguZmQVkO0"
   },
   "outputs": [],
   "source": [
    "def random_split(test_percent, valid_percent):\n",
    "    test_amount = int(total_players * test_percent)\n",
    "    valid_amount = int(total_players * valid_percent)\n",
    "    valid_sample = random.sample(range(0,total_players), test_amount + valid_amount)\n",
    "    test_sample = []\n",
    "    for i in range(test_amount):\n",
    "        test_sample.append(valid_sample.pop(0))\n",
    "    train_sample = [i for i in range(0, total_players)]\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    valid_x = []\n",
    "    valid_y = []\n",
    "    for idx in valid_sample:\n",
    "        train_sample.remove(idx)\n",
    "    for idx in test_sample:\n",
    "        train_sample.remove(idx)\n",
    "    print(\"Total: %d, Train: %d, Test: %d, Valid: %d\" % (total_players, len(train_sample), len(test_sample), len(valid_sample)))\n",
    "    for idx in test_sample:\n",
    "        test_x.append([one_hot(csv[\"team_abbreviation\"][idx], teams), one_hot(csv[\"college\"][idx], colleges), one_hot(csv[\"country\"][idx], countries),\n",
    "                   one_hot(csv[\"draft_year\"][idx], years), one_hot(csv[\"season\"][idx], seasons), float(csv[\"age\"][idx]),\n",
    "                   float(csv[\"player_height\"][idx]), float(csv[\"player_weight\"][idx]), float(csv[\"draft_round\"][idx]), float(csv[\"draft_number\"][idx]),\n",
    "                   float(csv[\"gp\"][idx]), float(csv[\"net_rating\"][idx]), float(csv[\"usg_pct\"][idx])])\n",
    "        test_y.append(torch.Tensor([float(csv[\"pts\"][idx]), float(csv[\"reb\"][idx]),\n",
    "                   float(csv[\"ast\"][idx]), float(csv[\"oreb_pct\"][idx]), float(csv[\"dreb_pct\"][idx]), float(csv[\"ts_pct\"][idx]), float(csv[\"ast_pct\"][idx])]))\n",
    "    for idx in train_sample:\n",
    "        train_x.append([one_hot(csv[\"team_abbreviation\"][idx], teams), one_hot(csv[\"college\"][idx], colleges), one_hot(csv[\"country\"][idx], countries),\n",
    "                   one_hot(csv[\"draft_year\"][idx], years), one_hot(csv[\"season\"][idx], seasons), float(csv[\"age\"][idx]),\n",
    "                   float(csv[\"player_height\"][idx]), float(csv[\"player_weight\"][idx]), float(csv[\"draft_round\"][idx]), float(csv[\"draft_number\"][idx]),\n",
    "                   float(csv[\"gp\"][idx]), float(csv[\"net_rating\"][idx]), float(csv[\"usg_pct\"][idx])])\n",
    "        train_y.append(torch.Tensor([float(csv[\"pts\"][idx]), float(csv[\"reb\"][idx]),\n",
    "                   float(csv[\"ast\"][idx]), float(csv[\"oreb_pct\"][idx]), float(csv[\"dreb_pct\"][idx]), float(csv[\"ts_pct\"][idx]), float(csv[\"ast_pct\"][idx])]))\n",
    "    for idx in valid_sample:\n",
    "        valid_x.append([one_hot(csv[\"team_abbreviation\"][idx], teams), one_hot(csv[\"college\"][idx], colleges), one_hot(csv[\"country\"][idx], countries),\n",
    "                   one_hot(csv[\"draft_year\"][idx], years), one_hot(csv[\"season\"][idx], seasons), float(csv[\"age\"][idx]),\n",
    "                   float(csv[\"player_height\"][idx]), float(csv[\"player_weight\"][idx]), float(csv[\"draft_round\"][idx]), float(csv[\"draft_number\"][idx]),\n",
    "                   float(csv[\"gp\"][idx]), float(csv[\"net_rating\"][idx]), float(csv[\"usg_pct\"][idx])])\n",
    "        valid_y.append(torch.Tensor([float(csv[\"pts\"][idx]), float(csv[\"reb\"][idx]),\n",
    "                   float(csv[\"ast\"][idx]), float(csv[\"oreb_pct\"][idx]), float(csv[\"dreb_pct\"][idx]), float(csv[\"ts_pct\"][idx]), float(csv[\"ast_pct\"][idx])]))\n",
    "    return train_x, train_y, test_x, test_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETNQDbVTtHJR",
    "outputId": "a4b9b9ee-4ac3-4de3-b95e-d7be20b239cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 11700, Train: 9360, Test: 1170, Valid: 1170\n",
      "CPU times: user 10.6 s, sys: 466 ms, total: 11 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%time train_x, train_y, test_x, test_y, valid_x, valid_y = random_split(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXJsCq65ZWKm"
   },
   "source": [
    "## Training and test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(neural_net, optimizer, loss, scheduler, train_features, train_labels, valid_features, valid_labels, epochs, batch_size, dropout=False):\n",
    "    xs = [i for i in range(epochs)]\n",
    "    ys = []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Starting epoch: \" + str(epoch))\n",
    "        count = 0\n",
    "        rl = 0.0\n",
    "        neural_net.train()\n",
    "        optimizer.zero_grad()\n",
    "        for i in range(len(train_labels)):\n",
    "            train_y = train_labels[i]\n",
    "            train_x = train_features[i]\n",
    "            output = neural_net(train_x)\n",
    "            out_loss = loss(output, train_y)\n",
    "            out_loss.backward()\n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            rl += out_loss.item()\n",
    "            if count % batch_size == 0:\n",
    "                optimizer.zero_grad()\n",
    "                print(str(count) + \" entries completed. Loss: \" + str(rl/batch_size))\n",
    "                rl = 0.0\n",
    "        scheduler.step()\n",
    "        epoch_loss = 0.0\n",
    "        neural_net.eval()\n",
    "        for i in range(len(valid_labels)):\n",
    "            valid_y = valid_labels[i]\n",
    "            valid_x = valid_features[i]\n",
    "            output = neural_net(valid_x)\n",
    "            epoch_loss += loss(output, valid_y)/float(len(valid_labels))\n",
    "            ys.append(epoch_loss)\n",
    "    return xs, ys\n",
    "\n",
    "def test(neural, test_x, test_y):\n",
    "    l = []\n",
    "    x = []\n",
    "    neural.eval()\n",
    "    for i in range(len(test_x)):\n",
    "        l.append(loss(neural(test_x[i]), test_y[i]).item())\n",
    "        x.append(i)\n",
    "    plt.hist(l, range(0,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "o3lRDT7abczZ"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.teamLin = nn.Linear(len(teams), 1)\n",
    "        self.collegeLin = nn.Linear(len(colleges), 1)\n",
    "        self.countryLin = nn.Linear(len(countries), 1)\n",
    "        self.draftLin = nn.Linear(len(years), 1)\n",
    "        self.seasonLin = nn.Linear(len(seasons), 1)\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(13, 20),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(20, 40),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(20, 7),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.Tensor([self.teamLin(x[0]), self.collegeLin(x[1]), self.countryLin(x[2]), self.draftLin(x[3]), self.seasonLin(x[4])] + x[5:])\n",
    "        return self.sequential(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5iMAYklzpqVI"
   },
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.teamLin = nn.Linear(len(teams), 1)\n",
    "        self.collegeLin = nn.Linear(len(colleges), 1)\n",
    "        self.countryLin = nn.Linear(len(countries), 1)\n",
    "        self.draftLin = nn.Linear(len(years), 1)\n",
    "        self.seasonLin = nn.Linear(len(seasons), 1)\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(13, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.Tensor([self.teamLin(x[0]), self.collegeLin(x[1]), self.countryLin(x[2]), self.draftLin(x[3]), self.seasonLin(x[4])] + x[5:])\n",
    "        return self.sequential(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "iXGBUuFtbeyq"
   },
   "outputs": [],
   "source": [
    "neural = NeuralNet()\n",
    "linnet = LinearNet()\n",
    "loss = nn.MSELoss()\n",
    "lin_loss = nn.MSELoss()\n",
    "lin_optim = optim.Adam(linnet.parameters())\n",
    "optimizer = optim.Adam(neural.parameters())\n",
    "n_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 completed. Loss: 3.758106556329876\n",
      "400 completed. Loss: 3.1487461547739803\n",
      "600 completed. Loss: 2.878018218991347\n",
      "800 completed. Loss: 3.101409283145331\n",
      "1000 completed. Loss: 3.3597923552244904\n",
      "1200 completed. Loss: 2.8457544357609006\n",
      "1400 completed. Loss: 2.95472631030716\n",
      "1600 completed. Loss: 2.9815937542542814\n",
      "1800 completed. Loss: 2.87779021338094\n",
      "2000 completed. Loss: 3.1262007633782924\n",
      "2200 completed. Loss: 2.9551464352803305\n",
      "2400 completed. Loss: 2.6991867704782635\n",
      "2600 completed. Loss: 3.0294234276236964\n",
      "2800 completed. Loss: 2.459375132927671\n",
      "3000 completed. Loss: 3.4112576047331093\n",
      "3200 completed. Loss: 2.8888103134743868\n",
      "3400 completed. Loss: 2.8847854163404554\n",
      "3600 completed. Loss: 3.6108315351698548\n",
      "3800 completed. Loss: 2.86822943248786\n",
      "4000 completed. Loss: 3.6626652802131137\n",
      "4200 completed. Loss: 2.802681380584836\n",
      "4400 completed. Loss: 3.180103890452301\n",
      "4600 completed. Loss: 3.664711179584265\n",
      "4800 completed. Loss: 3.255986802764237\n",
      "5000 completed. Loss: 3.1267780474293976\n",
      "5200 completed. Loss: 2.3919500158913434\n",
      "5400 completed. Loss: 2.8524903808906674\n",
      "5600 completed. Loss: 2.5704743632860483\n",
      "5800 completed. Loss: 2.860961717092432\n",
      "6000 completed. Loss: 2.4952991430740803\n",
      "6200 completed. Loss: 2.672706532762386\n",
      "6400 completed. Loss: 2.873947239194531\n",
      "6600 completed. Loss: 2.6901326123718174\n",
      "6800 completed. Loss: 2.59136201444082\n",
      "7000 completed. Loss: 2.6863548942282796\n",
      "7200 completed. Loss: 3.104590717423707\n",
      "7400 completed. Loss: 2.410160407628864\n",
      "7600 completed. Loss: 2.7368842716142536\n",
      "7800 completed. Loss: 2.875542013188824\n",
      "8000 completed. Loss: 2.951346578262746\n",
      "8200 completed. Loss: 4.403440004689619\n",
      "8400 completed. Loss: 2.8124781903089024\n",
      "8600 completed. Loss: 2.8491690351162107\n",
      "8800 completed. Loss: 2.7464897800423205\n",
      "9000 completed. Loss: 3.928173250844702\n",
      "9200 completed. Loss: 3.255668087946251\n",
      "200 completed. Loss: 3.4794146091863514\n",
      "400 completed. Loss: 3.0436898178234695\n",
      "600 completed. Loss: 3.144003924303688\n",
      "800 completed. Loss: 3.024489517379552\n",
      "1000 completed. Loss: 3.547925938065164\n",
      "1200 completed. Loss: 3.0504385470226407\n",
      "1400 completed. Loss: 2.951900078235194\n",
      "1600 completed. Loss: 2.707474188604392\n",
      "1800 completed. Loss: 3.0683068680018186\n",
      "2000 completed. Loss: 2.911838429882191\n",
      "2200 completed. Loss: 2.8886983663775028\n",
      "2400 completed. Loss: 2.6315776227321477\n",
      "2600 completed. Loss: 3.26500107425265\n",
      "2800 completed. Loss: 2.495331974583678\n",
      "3000 completed. Loss: 3.4135875729843974\n",
      "3200 completed. Loss: 2.844050841690041\n",
      "3400 completed. Loss: 3.176273937889491\n",
      "3600 completed. Loss: 3.6687313630012794\n",
      "3800 completed. Loss: 2.958348461603746\n",
      "4000 completed. Loss: 3.2536275811493396\n",
      "4200 completed. Loss: 2.770425737705082\n",
      "4400 completed. Loss: 3.3968458764627574\n",
      "4600 completed. Loss: 3.4313161990209484\n",
      "4800 completed. Loss: 3.2887942010350524\n",
      "5000 completed. Loss: 3.104218256343156\n",
      "5200 completed. Loss: 2.6221707439096646\n",
      "5400 completed. Loss: 3.3196971966978164\n",
      "5600 completed. Loss: 2.4644399667927064\n",
      "5800 completed. Loss: 2.8741379272658376\n",
      "6000 completed. Loss: 2.574837906770408\n",
      "6200 completed. Loss: 2.5858251251024194\n",
      "6400 completed. Loss: 3.013179843639955\n",
      "6600 completed. Loss: 2.768601622134447\n",
      "6800 completed. Loss: 2.624585709651001\n",
      "7000 completed. Loss: 2.6347967391926796\n",
      "7200 completed. Loss: 2.9442708709649743\n",
      "7400 completed. Loss: 2.56066138908267\n",
      "7600 completed. Loss: 2.7814493281836623\n",
      "7800 completed. Loss: 2.9383270565420387\n",
      "8000 completed. Loss: 3.1014680201373994\n",
      "8200 completed. Loss: 4.348154283619952\n",
      "8400 completed. Loss: 2.9819105053134263\n",
      "8600 completed. Loss: 2.952312367160339\n",
      "8800 completed. Loss: 2.8441269600577654\n",
      "9000 completed. Loss: 3.5257469072472305\n",
      "9200 completed. Loss: 3.2452944692363963\n",
      "200 completed. Loss: 3.557328314566985\n",
      "400 completed. Loss: 3.100059653525241\n",
      "600 completed. Loss: 3.060842395760119\n",
      "800 completed. Loss: 2.710292447600514\n",
      "1000 completed. Loss: 3.607329076286405\n",
      "1200 completed. Loss: 3.113349312939681\n",
      "1400 completed. Loss: 2.9658403919171543\n",
      "1600 completed. Loss: 2.786334671555087\n",
      "1800 completed. Loss: 3.19613969638478\n",
      "2000 completed. Loss: 2.8879050562437625\n",
      "2200 completed. Loss: 3.2381830843910575\n",
      "2400 completed. Loss: 2.5082872326951473\n",
      "2600 completed. Loss: 3.066443140562624\n",
      "2800 completed. Loss: 2.2781555525341535\n",
      "3000 completed. Loss: 3.281048552240245\n",
      "3200 completed. Loss: 2.6299435390648433\n",
      "3400 completed. Loss: 2.925919637605548\n",
      "3600 completed. Loss: 3.081949510090053\n",
      "3800 completed. Loss: 2.724368520947173\n",
      "4000 completed. Loss: 3.472523990403861\n",
      "4200 completed. Loss: 2.887174295112491\n",
      "4400 completed. Loss: 3.4159491293225437\n",
      "4600 completed. Loss: 3.148033367181197\n",
      "4800 completed. Loss: 3.3054819751158355\n",
      "5000 completed. Loss: 2.89654530887492\n",
      "5200 completed. Loss: 2.7323763786721975\n",
      "5400 completed. Loss: 3.0133920038864015\n",
      "5600 completed. Loss: 2.5084221329679712\n",
      "5800 completed. Loss: 2.876255186838098\n",
      "6000 completed. Loss: 2.4367551185935734\n",
      "6200 completed. Loss: 2.5897854241490132\n",
      "6400 completed. Loss: 3.25312887578737\n",
      "6600 completed. Loss: 2.601521915476769\n",
      "6800 completed. Loss: 2.352689422611147\n",
      "7000 completed. Loss: 2.4434560644067824\n",
      "7200 completed. Loss: 3.049487599232234\n",
      "7400 completed. Loss: 2.238568426971324\n",
      "7600 completed. Loss: 2.8205324718542397\n",
      "7800 completed. Loss: 2.935807967633009\n",
      "8000 completed. Loss: 3.330554508187342\n",
      "8200 completed. Loss: 3.7402179908007382\n",
      "8400 completed. Loss: 2.847359578832984\n",
      "8600 completed. Loss: 2.7940202389191837\n",
      "8800 completed. Loss: 2.7348764766659586\n",
      "9000 completed. Loss: 3.7521168777067215\n",
      "9200 completed. Loss: 3.040667978040874\n",
      "200 completed. Loss: 3.840229858979583\n",
      "400 completed. Loss: 3.207859778702259\n",
      "600 completed. Loss: 3.1788362650340423\n",
      "800 completed. Loss: 2.8991332039469855\n",
      "1000 completed. Loss: 3.5313492231722923\n",
      "1200 completed. Loss: 2.8643800491141156\n",
      "1400 completed. Loss: 3.08535105963645\n",
      "1600 completed. Loss: 2.7068039462529123\n",
      "1800 completed. Loss: 3.344951861035079\n",
      "2000 completed. Loss: 2.916858327141963\n",
      "2200 completed. Loss: 3.223060160195455\n",
      "2400 completed. Loss: 2.530031832465902\n",
      "2600 completed. Loss: 3.3820535509334877\n",
      "2800 completed. Loss: 2.544959365548566\n",
      "3000 completed. Loss: 3.453751121927053\n",
      "3200 completed. Loss: 3.0772134279552845\n",
      "3400 completed. Loss: 3.019399159658933\n",
      "3600 completed. Loss: 3.1263989950157702\n",
      "3800 completed. Loss: 3.236760174697265\n",
      "4000 completed. Loss: 3.593364500030875\n",
      "4200 completed. Loss: 2.7446715147327634\n",
      "4400 completed. Loss: 3.2828115605167114\n",
      "4600 completed. Loss: 3.3402094833832234\n",
      "4800 completed. Loss: 3.336800900455564\n",
      "5000 completed. Loss: 3.2126954720169305\n",
      "5200 completed. Loss: 2.790022810790688\n",
      "5400 completed. Loss: 3.338104838710278\n",
      "5600 completed. Loss: 2.4073990872409197\n",
      "5800 completed. Loss: 2.995830119282473\n",
      "6000 completed. Loss: 2.475086040897295\n",
      "6200 completed. Loss: 2.8537413762742654\n",
      "6400 completed. Loss: 3.3227571466844528\n",
      "6600 completed. Loss: 2.8346161863766612\n",
      "6800 completed. Loss: 2.316178653035313\n",
      "7000 completed. Loss: 2.5373192427493634\n",
      "7200 completed. Loss: 2.9413456483744085\n",
      "7400 completed. Loss: 2.382450394202024\n",
      "7600 completed. Loss: 2.861273923199624\n",
      "7800 completed. Loss: 3.032152354102582\n",
      "8000 completed. Loss: 3.11392621897161\n",
      "8200 completed. Loss: 4.458354359520599\n",
      "8400 completed. Loss: 2.964936910740798\n",
      "8600 completed. Loss: 2.9078134953882544\n",
      "8800 completed. Loss: 2.869769801888615\n",
      "9000 completed. Loss: 3.3406328327953814\n",
      "9200 completed. Loss: 2.947417227467522\n",
      "200 completed. Loss: 3.818161177104339\n",
      "400 completed. Loss: 3.154092666786164\n",
      "600 completed. Loss: 3.1167013682052493\n",
      "800 completed. Loss: 2.959639744730666\n",
      "1000 completed. Loss: 3.174986707018688\n",
      "1200 completed. Loss: 3.024844677196816\n",
      "1400 completed. Loss: 3.0064715788699687\n",
      "1600 completed. Loss: 2.6593511595390735\n",
      "1800 completed. Loss: 2.911028996119276\n",
      "2000 completed. Loss: 3.0811870439909397\n",
      "2200 completed. Loss: 3.083738596988842\n",
      "2400 completed. Loss: 2.6201870320830496\n",
      "2600 completed. Loss: 2.898334818794392\n",
      "2800 completed. Loss: 2.3488841874618083\n",
      "3000 completed. Loss: 3.2658619456691667\n",
      "3200 completed. Loss: 3.1172433945501687\n",
      "3400 completed. Loss: 2.8249124635849148\n",
      "3600 completed. Loss: 3.260134299658239\n",
      "3800 completed. Loss: 2.8650622310955076\n",
      "4000 completed. Loss: 3.3119602235103955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 completed. Loss: 2.6904886929085476\n",
      "4400 completed. Loss: 3.468752370039001\n",
      "4600 completed. Loss: 3.3952147593558766\n",
      "4800 completed. Loss: 3.1185559968650343\n",
      "5000 completed. Loss: 3.020670316880569\n",
      "5200 completed. Loss: 2.581100304299034\n",
      "5400 completed. Loss: 3.258101178277284\n",
      "5600 completed. Loss: 2.3349518092535435\n",
      "5800 completed. Loss: 3.0125332855572924\n",
      "6000 completed. Loss: 2.675381182860583\n",
      "6200 completed. Loss: 2.7309880468202756\n",
      "6400 completed. Loss: 3.096873316569254\n",
      "6600 completed. Loss: 2.7718248991668224\n",
      "6800 completed. Loss: 2.3315440676547587\n",
      "7000 completed. Loss: 2.7895047359541056\n",
      "7200 completed. Loss: 2.846486782329157\n",
      "7400 completed. Loss: 2.431878485698253\n",
      "7600 completed. Loss: 2.5972127796523274\n",
      "7800 completed. Loss: 3.1695560396090148\n",
      "8000 completed. Loss: 3.005901746880263\n",
      "8200 completed. Loss: 3.9527356902323665\n",
      "8400 completed. Loss: 2.996707566510886\n",
      "8600 completed. Loss: 2.841090776268393\n",
      "8800 completed. Loss: 2.845147115662694\n",
      "9000 completed. Loss: 3.613678398001939\n",
      "9200 completed. Loss: 3.045004290342331\n",
      "200 completed. Loss: 3.9192238087579607\n",
      "400 completed. Loss: 3.223039379478432\n",
      "600 completed. Loss: 3.2702429841691627\n",
      "800 completed. Loss: 2.923402131712064\n",
      "1000 completed. Loss: 3.191594819156453\n",
      "1200 completed. Loss: 2.951841890402138\n",
      "1400 completed. Loss: 2.662180581962457\n",
      "1600 completed. Loss: 2.691637639068067\n",
      "1800 completed. Loss: 3.0124444440566003\n",
      "2000 completed. Loss: 3.1502424146817067\n",
      "2200 completed. Loss: 2.9178598537109792\n",
      "2400 completed. Loss: 2.5113097814982757\n",
      "2600 completed. Loss: 3.143582251695916\n",
      "2800 completed. Loss: 2.602856390736997\n",
      "3000 completed. Loss: 3.4167957318387927\n",
      "3200 completed. Loss: 2.8670957225281746\n",
      "3400 completed. Loss: 2.8516357110626998\n",
      "3600 completed. Loss: 3.301753071639687\n",
      "3800 completed. Loss: 3.212725381292403\n",
      "4000 completed. Loss: 3.3540504046622663\n",
      "4200 completed. Loss: 2.673600036147982\n",
      "4400 completed. Loss: 3.4679954271018505\n",
      "4600 completed. Loss: 3.401745099751279\n",
      "4800 completed. Loss: 3.1656935906922445\n",
      "5000 completed. Loss: 2.9553141184174456\n",
      "5200 completed. Loss: 2.786160112861544\n",
      "5400 completed. Loss: 3.034827425330877\n",
      "5600 completed. Loss: 2.457753201117739\n",
      "5800 completed. Loss: 2.7874312635883687\n",
      "6000 completed. Loss: 2.5573990235850217\n",
      "6200 completed. Loss: 2.70253475388512\n",
      "6400 completed. Loss: 3.1739576169196515\n",
      "6600 completed. Loss: 2.6161644953489303\n",
      "6800 completed. Loss: 2.2233267570845783\n",
      "7000 completed. Loss: 2.7370514294691386\n",
      "7200 completed. Loss: 3.0830163617432116\n",
      "7400 completed. Loss: 2.2826476138085128\n",
      "7600 completed. Loss: 2.748898331997916\n",
      "7800 completed. Loss: 2.8197459153831006\n",
      "8000 completed. Loss: 3.2674465732509272\n",
      "8200 completed. Loss: 4.099140284191817\n",
      "8400 completed. Loss: 2.8495517736673355\n",
      "8600 completed. Loss: 2.728577803364024\n",
      "8800 completed. Loss: 2.9729513672925534\n",
      "9000 completed. Loss: 3.571201840210706\n",
      "9200 completed. Loss: 3.191264347950928\n",
      "200 completed. Loss: 3.635776763278991\n",
      "400 completed. Loss: 3.258331551719457\n",
      "600 completed. Loss: 3.1031959027051927\n",
      "800 completed. Loss: 2.861544149313122\n",
      "1000 completed. Loss: 3.4343290558923036\n",
      "1200 completed. Loss: 2.9942167524434624\n",
      "1400 completed. Loss: 2.6604684084188195\n",
      "1600 completed. Loss: 2.745693501587957\n",
      "1800 completed. Loss: 3.360795033890754\n",
      "2000 completed. Loss: 3.1674853195808828\n",
      "2200 completed. Loss: 3.1664502619067205\n",
      "2400 completed. Loss: 2.544658955200575\n",
      "2600 completed. Loss: 2.9077890410181135\n",
      "2800 completed. Loss: 2.410059209014289\n",
      "3000 completed. Loss: 3.5935600025951864\n",
      "3200 completed. Loss: 3.20630593014881\n",
      "3400 completed. Loss: 2.876299185459502\n",
      "3600 completed. Loss: 3.563342761793174\n",
      "3800 completed. Loss: 3.0080858906544745\n",
      "4000 completed. Loss: 3.5759064791258424\n",
      "4200 completed. Loss: 2.7498333692085\n",
      "4400 completed. Loss: 3.1882335062650964\n",
      "4600 completed. Loss: 3.5733218725537883\n",
      "4800 completed. Loss: 3.0841587677411737\n",
      "5000 completed. Loss: 2.977517701543402\n",
      "5200 completed. Loss: 2.6018087648018264\n",
      "5400 completed. Loss: 2.979012703592889\n",
      "5600 completed. Loss: 2.60011753315106\n",
      "5800 completed. Loss: 2.7134217480383813\n",
      "6000 completed. Loss: 2.7288233385793865\n",
      "6200 completed. Loss: 2.811922768726945\n",
      "6400 completed. Loss: 3.1444490990368648\n",
      "6600 completed. Loss: 2.67069179312326\n",
      "6800 completed. Loss: 2.543120455518365\n",
      "7000 completed. Loss: 2.509515702649951\n",
      "7200 completed. Loss: 3.022310699936934\n",
      "7400 completed. Loss: 2.5415024922601877\n",
      "7600 completed. Loss: 2.652987449709326\n",
      "7800 completed. Loss: 3.174343568664044\n",
      "8000 completed. Loss: 3.0611949042603372\n",
      "8200 completed. Loss: 4.21917318393942\n",
      "8400 completed. Loss: 2.860542073706165\n",
      "8600 completed. Loss: 2.7570492683071643\n",
      "8800 completed. Loss: 2.913340396862477\n",
      "9000 completed. Loss: 3.884778943490237\n",
      "9200 completed. Loss: 3.0112484731245788\n",
      "200 completed. Loss: 3.6761651708185674\n",
      "400 completed. Loss: 3.281192943677306\n",
      "600 completed. Loss: 3.4486533535458146\n",
      "800 completed. Loss: 2.9498610256658866\n",
      "1000 completed. Loss: 3.12765129432315\n",
      "1200 completed. Loss: 3.22335387758445\n",
      "1400 completed. Loss: 2.9112120610522108\n",
      "1600 completed. Loss: 3.0101201771665362\n",
      "1800 completed. Loss: 2.8262902127206324\n",
      "2000 completed. Loss: 3.036874093990773\n",
      "2200 completed. Loss: 3.0470898980926724\n",
      "2400 completed. Loss: 2.5562198749464007\n",
      "2600 completed. Loss: 2.993772027855739\n",
      "2800 completed. Loss: 2.4421899188961835\n",
      "3000 completed. Loss: 3.426258420967497\n",
      "3200 completed. Loss: 2.8824222825258037\n",
      "3400 completed. Loss: 2.920155488662422\n",
      "3600 completed. Loss: 3.3271029406809247\n",
      "3800 completed. Loss: 3.3800918663851918\n",
      "4000 completed. Loss: 3.245824838448316\n",
      "4200 completed. Loss: 2.8891159951500596\n",
      "4400 completed. Loss: 3.3298405048623683\n",
      "4600 completed. Loss: 3.5962231433205307\n",
      "4800 completed. Loss: 3.3415349971130492\n",
      "5000 completed. Loss: 2.910435210186988\n",
      "5200 completed. Loss: 2.6913398418575527\n",
      "5400 completed. Loss: 2.871621865089983\n",
      "5600 completed. Loss: 2.6359025900624693\n",
      "5800 completed. Loss: 3.00486525204964\n",
      "6000 completed. Loss: 2.619605778418481\n",
      "6200 completed. Loss: 2.5563272475264966\n",
      "6400 completed. Loss: 2.883378501147963\n",
      "6600 completed. Loss: 2.57063684489578\n",
      "6800 completed. Loss: 2.420293266330846\n",
      "7000 completed. Loss: 2.744701803466305\n",
      "7200 completed. Loss: 3.0412110736593605\n",
      "7400 completed. Loss: 2.3226201051706448\n",
      "7600 completed. Loss: 2.793755720863119\n",
      "7800 completed. Loss: 2.9435790699534117\n",
      "8000 completed. Loss: 3.454436544012278\n",
      "8200 completed. Loss: 4.237897931616754\n",
      "8400 completed. Loss: 2.8156020685168914\n",
      "8600 completed. Loss: 2.679098283033818\n",
      "8800 completed. Loss: 2.917682774811983\n",
      "9000 completed. Loss: 3.5603769312100484\n",
      "9200 completed. Loss: 3.084480767166242\n",
      "200 completed. Loss: 3.6305572690069674\n",
      "400 completed. Loss: 3.5552028606692327\n",
      "600 completed. Loss: 3.2644263291731477\n",
      "800 completed. Loss: 3.104152190638706\n",
      "1000 completed. Loss: 3.213312940550968\n",
      "1200 completed. Loss: 2.8542915803939106\n",
      "1400 completed. Loss: 3.0488567926129324\n",
      "1600 completed. Loss: 2.8563739708717915\n",
      "1800 completed. Loss: 2.7084425993543118\n",
      "2000 completed. Loss: 3.193607448814437\n",
      "2200 completed. Loss: 2.945269724577665\n",
      "2400 completed. Loss: 2.5037772713787856\n",
      "2600 completed. Loss: 3.12118886237964\n",
      "2800 completed. Loss: 2.6160807143431155\n",
      "3000 completed. Loss: 3.487492181155831\n",
      "3200 completed. Loss: 2.8154962477646768\n",
      "3400 completed. Loss: 2.890765377143398\n",
      "3600 completed. Loss: 3.214077334061731\n",
      "3800 completed. Loss: 3.0200150796212255\n",
      "4000 completed. Loss: 3.479246391542256\n",
      "4200 completed. Loss: 2.78663617930375\n",
      "4400 completed. Loss: 3.2444925838382916\n",
      "4600 completed. Loss: 3.2819637225812768\n",
      "4800 completed. Loss: 3.110761961033568\n",
      "5000 completed. Loss: 3.0142826045583933\n",
      "5200 completed. Loss: 2.716207152279094\n",
      "5400 completed. Loss: 3.063653682228178\n",
      "5600 completed. Loss: 2.6389278860297054\n",
      "5800 completed. Loss: 3.020813606195152\n",
      "6000 completed. Loss: 2.5459811830770924\n",
      "6200 completed. Loss: 2.5177730226237327\n",
      "6400 completed. Loss: 3.0511008133925497\n",
      "6600 completed. Loss: 2.6187984691699966\n",
      "6800 completed. Loss: 2.2547309957328254\n",
      "7000 completed. Loss: 2.554505688166246\n",
      "7200 completed. Loss: 3.0170570559008048\n",
      "7400 completed. Loss: 2.484326096009463\n",
      "7600 completed. Loss: 2.666894561953377\n",
      "7800 completed. Loss: 3.0442556228674946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 completed. Loss: 3.3091157240234317\n",
      "8200 completed. Loss: 4.046355178337544\n",
      "8400 completed. Loss: 2.8071224999800326\n",
      "8600 completed. Loss: 2.80314037790522\n",
      "8800 completed. Loss: 3.0000135865900663\n",
      "9000 completed. Loss: 3.9783126241574065\n",
      "9200 completed. Loss: 3.014108053939417\n",
      "200 completed. Loss: 3.764233722910285\n",
      "400 completed. Loss: 3.414581710640341\n",
      "600 completed. Loss: 3.5596544160414485\n",
      "800 completed. Loss: 3.1665602591075004\n",
      "1000 completed. Loss: 3.4202418386144564\n",
      "1200 completed. Loss: 3.0314277008362116\n",
      "1400 completed. Loss: 3.1691751885320993\n",
      "1600 completed. Loss: 2.9354623397812247\n",
      "1800 completed. Loss: 3.2253313715942205\n",
      "2000 completed. Loss: 2.9589938992750833\n",
      "2200 completed. Loss: 2.7417506026662886\n",
      "2400 completed. Loss: 2.43259603491053\n",
      "2600 completed. Loss: 2.978040556279011\n",
      "2800 completed. Loss: 2.537402422185987\n",
      "3000 completed. Loss: 3.4307124999258667\n",
      "3200 completed. Loss: 2.9140332141821275\n",
      "3400 completed. Loss: 2.9603853230178356\n",
      "3600 completed. Loss: 3.1110826393868773\n",
      "3800 completed. Loss: 3.2859117060899736\n",
      "4000 completed. Loss: 3.2190896846633406\n",
      "4200 completed. Loss: 2.7767917088605465\n",
      "4400 completed. Loss: 3.46750637948513\n",
      "4600 completed. Loss: 3.3143018941697666\n",
      "4800 completed. Loss: 3.1246225395426155\n",
      "5000 completed. Loss: 2.960909835267812\n",
      "5200 completed. Loss: 2.5912617499008777\n",
      "5400 completed. Loss: 3.0496596116386354\n",
      "5600 completed. Loss: 2.5719317204598338\n",
      "5800 completed. Loss: 3.0680124470684675\n",
      "6000 completed. Loss: 2.501276464983821\n",
      "6200 completed. Loss: 2.699837207458913\n",
      "6400 completed. Loss: 3.073023008964956\n",
      "6600 completed. Loss: 2.417844018721953\n",
      "6800 completed. Loss: 2.3637873500678688\n",
      "7000 completed. Loss: 2.8600400912063195\n",
      "7200 completed. Loss: 2.808434024164453\n",
      "7400 completed. Loss: 2.278199036074802\n",
      "7600 completed. Loss: 2.678681168705225\n",
      "7800 completed. Loss: 2.973768088999204\n",
      "8000 completed. Loss: 3.3545268071629106\n",
      "8200 completed. Loss: 3.7825748852733523\n",
      "8400 completed. Loss: 2.759968035612255\n",
      "8600 completed. Loss: 2.6364759946987033\n",
      "8800 completed. Loss: 2.842798440260813\n",
      "9000 completed. Loss: 3.811615710258484\n",
      "9200 completed. Loss: 3.1993316510948353\n",
      "200 completed. Loss: 3.9347630287334323\n",
      "400 completed. Loss: 3.4296181107312442\n",
      "600 completed. Loss: 3.4337901560217143\n",
      "800 completed. Loss: 2.9377697310829536\n",
      "1000 completed. Loss: 3.405384483479429\n",
      "1200 completed. Loss: 3.040667796470225\n",
      "1400 completed. Loss: 2.855274358987808\n",
      "1600 completed. Loss: 2.774586439151317\n",
      "1800 completed. Loss: 2.963786243345821\n",
      "2000 completed. Loss: 2.88899302310776\n",
      "2200 completed. Loss: 2.959633176671341\n",
      "2400 completed. Loss: 2.5759432738786563\n",
      "2600 completed. Loss: 2.840254367813468\n",
      "2800 completed. Loss: 2.437064644750208\n",
      "3000 completed. Loss: 3.3264274541288614\n",
      "3200 completed. Loss: 2.9416242849268017\n",
      "3400 completed. Loss: 2.917332379873842\n",
      "3600 completed. Loss: 3.22854113987647\n",
      "3800 completed. Loss: 3.2623560021445157\n",
      "4000 completed. Loss: 3.3561458000913262\n",
      "4200 completed. Loss: 2.743366102948785\n",
      "4400 completed. Loss: 3.5340482187457383\n",
      "4600 completed. Loss: 3.441126268086955\n",
      "4800 completed. Loss: 3.3968914783513173\n",
      "5000 completed. Loss: 2.9049766689073295\n",
      "5200 completed. Loss: 2.756670588012785\n",
      "5400 completed. Loss: 3.0171027390658853\n",
      "5600 completed. Loss: 2.509092615954578\n",
      "5800 completed. Loss: 2.952138512721285\n",
      "6000 completed. Loss: 2.3782569321990015\n",
      "6200 completed. Loss: 2.6771529477834703\n",
      "6400 completed. Loss: 3.1512192598357798\n",
      "6600 completed. Loss: 2.5684537262748925\n",
      "6800 completed. Loss: 2.4753511148132383\n",
      "7000 completed. Loss: 2.680411527531687\n",
      "7200 completed. Loss: 2.797777502532117\n",
      "7400 completed. Loss: 2.377073766672984\n",
      "7600 completed. Loss: 2.8817868544440715\n",
      "7800 completed. Loss: 3.0455724352423568\n",
      "8000 completed. Loss: 3.1248606710089373\n",
      "8200 completed. Loss: 3.774838077761233\n",
      "8400 completed. Loss: 3.152267034482211\n",
      "8600 completed. Loss: 2.5868593343999238\n",
      "8800 completed. Loss: 2.9099258076399566\n",
      "9000 completed. Loss: 3.740282809128985\n",
      "9200 completed. Loss: 3.0133020069729537\n",
      "200 completed. Loss: 3.6676345829293133\n",
      "400 completed. Loss: 3.33389002576936\n",
      "600 completed. Loss: 3.3904129615984857\n",
      "800 completed. Loss: 2.8437973138317467\n",
      "1000 completed. Loss: 3.1991615242374247\n",
      "1200 completed. Loss: 3.0532343207579107\n",
      "1400 completed. Loss: 3.0192493399837987\n",
      "1600 completed. Loss: 2.6026982499379665\n",
      "1800 completed. Loss: 3.045596955595538\n",
      "2000 completed. Loss: 3.1068408820219338\n",
      "2200 completed. Loss: 2.9766988179273906\n",
      "2400 completed. Loss: 2.620832061972469\n",
      "2600 completed. Loss: 2.9693292318319435\n",
      "2800 completed. Loss: 2.643816020251252\n",
      "3000 completed. Loss: 3.15893907899037\n",
      "3200 completed. Loss: 2.9051906955009326\n",
      "3400 completed. Loss: 2.8489044050505616\n",
      "3600 completed. Loss: 3.168842186022084\n",
      "3800 completed. Loss: 3.4024250391405078\n",
      "4000 completed. Loss: 3.4199377493187786\n",
      "4200 completed. Loss: 2.750656832479872\n",
      "4400 completed. Loss: 3.3280198882333933\n",
      "4600 completed. Loss: 3.362446252409136\n",
      "4800 completed. Loss: 3.328413235627813\n",
      "5000 completed. Loss: 3.1293101675761865\n",
      "5200 completed. Loss: 2.5865475978702306\n",
      "5400 completed. Loss: 2.970890712784603\n",
      "5600 completed. Loss: 2.8616436378844083\n",
      "5800 completed. Loss: 2.854902589181438\n",
      "6000 completed. Loss: 2.502876089559868\n",
      "6200 completed. Loss: 2.6427544402331113\n",
      "6400 completed. Loss: 3.051384641118348\n",
      "6600 completed. Loss: 2.552009835541248\n",
      "6800 completed. Loss: 2.4211476374883203\n",
      "7000 completed. Loss: 2.455367125575431\n",
      "7200 completed. Loss: 3.0031190311163662\n",
      "7400 completed. Loss: 2.4168368236720563\n",
      "7600 completed. Loss: 2.7212609189283103\n",
      "7800 completed. Loss: 3.1065969678387044\n",
      "8000 completed. Loss: 3.428153088521212\n",
      "8200 completed. Loss: 3.8652717695152385\n",
      "8400 completed. Loss: 3.005165419068653\n",
      "8600 completed. Loss: 2.760176431830041\n",
      "8800 completed. Loss: 2.843177828071639\n",
      "9000 completed. Loss: 4.081762341624126\n",
      "9200 completed. Loss: 3.1860851563327013\n",
      "200 completed. Loss: 3.3794478833675385\n",
      "400 completed. Loss: 3.45033921463415\n",
      "600 completed. Loss: 3.4716436982899905\n",
      "800 completed. Loss: 2.919913986446336\n",
      "1000 completed. Loss: 3.2953953175852075\n",
      "1200 completed. Loss: 3.019404023103416\n",
      "1400 completed. Loss: 2.906990983290598\n",
      "1600 completed. Loss: 3.0117537535959853\n",
      "1800 completed. Loss: 3.168051059152931\n",
      "2000 completed. Loss: 3.0016375220823104\n",
      "2200 completed. Loss: 3.0556414604373274\n",
      "2400 completed. Loss: 2.5279398350184783\n",
      "2600 completed. Loss: 3.004283826362807\n",
      "2800 completed. Loss: 2.387773150075227\n",
      "3000 completed. Loss: 3.2412224112264814\n",
      "3200 completed. Loss: 2.6415127909742298\n",
      "3400 completed. Loss: 2.6905351719260215\n",
      "3600 completed. Loss: 3.139181337719783\n",
      "3800 completed. Loss: 2.9031152007868513\n",
      "4000 completed. Loss: 3.5063511877320708\n",
      "4200 completed. Loss: 2.771253431448713\n",
      "4400 completed. Loss: 3.3947462710272522\n",
      "4600 completed. Loss: 3.3784342485480012\n",
      "4800 completed. Loss: 3.0252101792860775\n",
      "5000 completed. Loss: 3.044393666256219\n",
      "5200 completed. Loss: 2.5790581158548593\n",
      "5400 completed. Loss: 3.045888894582167\n",
      "5600 completed. Loss: 2.569148540524766\n",
      "5800 completed. Loss: 3.020764555130154\n",
      "6000 completed. Loss: 2.7450190756004305\n",
      "6200 completed. Loss: 2.887741853343323\n",
      "6400 completed. Loss: 2.94324188911356\n",
      "6600 completed. Loss: 2.624171408023685\n",
      "6800 completed. Loss: 2.5130334790889175\n",
      "7000 completed. Loss: 2.542446472607553\n",
      "7200 completed. Loss: 2.835096769966185\n",
      "7400 completed. Loss: 2.3268039203621447\n",
      "7600 completed. Loss: 2.8508603051956745\n",
      "7800 completed. Loss: 2.9654877892602234\n",
      "8000 completed. Loss: 3.0736920989851932\n",
      "8200 completed. Loss: 4.084986013481394\n",
      "8400 completed. Loss: 2.9302210856461897\n",
      "8600 completed. Loss: 3.0043278692942113\n",
      "8800 completed. Loss: 2.7663448870088905\n",
      "9000 completed. Loss: 3.4102373809274287\n",
      "9200 completed. Loss: 3.213742431839928\n",
      "200 completed. Loss: 3.4145336498739196\n",
      "400 completed. Loss: 3.301947229122743\n",
      "600 completed. Loss: 3.357895495221019\n",
      "800 completed. Loss: 3.1375747850351035\n",
      "1000 completed. Loss: 3.534369415040128\n",
      "1200 completed. Loss: 2.896146683553234\n",
      "1400 completed. Loss: 3.120539024900645\n",
      "1600 completed. Loss: 2.8800145580759273\n",
      "1800 completed. Loss: 3.3161308571416885\n",
      "2000 completed. Loss: 3.0725813495600596\n",
      "2200 completed. Loss: 2.7844033365231007\n",
      "2400 completed. Loss: 2.8790901284571735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 completed. Loss: 3.120380462505855\n",
      "2800 completed. Loss: 2.350163460187614\n",
      "3000 completed. Loss: 3.460977664438542\n",
      "3200 completed. Loss: 2.694097538776696\n",
      "3400 completed. Loss: 3.0246724120364523\n",
      "3600 completed. Loss: 3.205752496276982\n",
      "3800 completed. Loss: 3.281409535575658\n",
      "4000 completed. Loss: 3.258612387413159\n",
      "4200 completed. Loss: 2.9382033705152573\n",
      "4400 completed. Loss: 3.3968598961643877\n",
      "4600 completed. Loss: 3.3047651978675274\n",
      "4800 completed. Loss: 3.0439774234639483\n",
      "5000 completed. Loss: 2.9774576789233835\n",
      "5200 completed. Loss: 2.6146018891315905\n",
      "5400 completed. Loss: 3.230738071263768\n",
      "5600 completed. Loss: 2.577993352562189\n",
      "5800 completed. Loss: 3.0082332452014087\n",
      "6000 completed. Loss: 2.525600185380317\n",
      "6200 completed. Loss: 2.7272996399505063\n",
      "6400 completed. Loss: 3.213496867278591\n",
      "6600 completed. Loss: 2.5894606254436074\n",
      "6800 completed. Loss: 2.6956594668701293\n",
      "7000 completed. Loss: 2.615707869883627\n",
      "7200 completed. Loss: 2.9939818167313934\n",
      "7400 completed. Loss: 2.4748009181395174\n",
      "7600 completed. Loss: 2.8172611679323016\n",
      "7800 completed. Loss: 2.9908967735804617\n",
      "8000 completed. Loss: 3.281627193335444\n",
      "8200 completed. Loss: 3.9559463495202363\n",
      "8400 completed. Loss: 2.8257857670634987\n",
      "8600 completed. Loss: 2.6478194812498987\n",
      "8800 completed. Loss: 2.864384476756677\n",
      "9000 completed. Loss: 3.698830565363169\n",
      "9200 completed. Loss: 2.9704303917568176\n",
      "200 completed. Loss: 3.440070002544671\n",
      "400 completed. Loss: 3.328314612079412\n",
      "600 completed. Loss: 3.3980064550973474\n",
      "800 completed. Loss: 2.975369624681771\n",
      "1000 completed. Loss: 3.1100297989696264\n",
      "1200 completed. Loss: 3.054871636601165\n",
      "1400 completed. Loss: 2.988118291804567\n",
      "1600 completed. Loss: 2.7671106998529287\n",
      "1800 completed. Loss: 3.2166234199842436\n",
      "2000 completed. Loss: 3.0077590000629426\n",
      "2200 completed. Loss: 2.802337711621076\n",
      "2400 completed. Loss: 2.748823057645932\n",
      "2600 completed. Loss: 3.1396500988141636\n",
      "2800 completed. Loss: 2.6582283534156157\n",
      "3000 completed. Loss: 3.4082225193083286\n",
      "3200 completed. Loss: 2.8306317226588726\n",
      "3400 completed. Loss: 3.0127857583016158\n",
      "3600 completed. Loss: 3.222150171897374\n",
      "3800 completed. Loss: 3.3562179749365897\n",
      "4000 completed. Loss: 3.559058320466429\n",
      "4200 completed. Loss: 2.7148516284208744\n",
      "4400 completed. Loss: 3.2861809563077986\n",
      "4600 completed. Loss: 3.596915719099343\n",
      "4800 completed. Loss: 3.068136099334806\n",
      "5000 completed. Loss: 3.0523528193682434\n",
      "5200 completed. Loss: 2.4850090602599084\n",
      "5400 completed. Loss: 3.027581705581397\n",
      "5600 completed. Loss: 2.652348610730842\n",
      "5800 completed. Loss: 2.9470502510038203\n",
      "6000 completed. Loss: 2.4808163909986614\n",
      "6200 completed. Loss: 2.7284355095680803\n",
      "6400 completed. Loss: 3.020077111236751\n",
      "6600 completed. Loss: 2.6019353029783816\n",
      "6800 completed. Loss: 2.236533608501777\n",
      "7000 completed. Loss: 2.441296956911683\n",
      "7200 completed. Loss: 2.8250304723531006\n",
      "7400 completed. Loss: 2.3265859189629556\n",
      "7600 completed. Loss: 2.7811563204880803\n",
      "7800 completed. Loss: 2.9606017556600275\n",
      "8000 completed. Loss: 3.2654143988434225\n",
      "8200 completed. Loss: 4.49754457898438\n",
      "8400 completed. Loss: 2.649601018456742\n",
      "8600 completed. Loss: 2.8802115643222352\n",
      "8800 completed. Loss: 3.1608365748263894\n",
      "9000 completed. Loss: 3.4121855453494936\n",
      "9200 completed. Loss: 3.0461700404365546\n",
      "200 completed. Loss: 3.3696889979951083\n",
      "400 completed. Loss: 3.5106657517328856\n",
      "600 completed. Loss: 3.387827656911686\n",
      "800 completed. Loss: 3.108437989000231\n",
      "1000 completed. Loss: 3.2128399870637803\n",
      "1200 completed. Loss: 3.2380431110784413\n",
      "1400 completed. Loss: 3.1724424619227647\n",
      "1600 completed. Loss: 2.7164991908241065\n",
      "1800 completed. Loss: 3.3166420638165435\n",
      "2000 completed. Loss: 3.2081673923460765\n",
      "2200 completed. Loss: 2.959015833027661\n",
      "2400 completed. Loss: 3.0113411826780068\n",
      "2600 completed. Loss: 2.9101408043596892\n",
      "2800 completed. Loss: 2.519892195118591\n",
      "3000 completed. Loss: 3.538948276946321\n",
      "3200 completed. Loss: 2.818745262492448\n",
      "3400 completed. Loss: 2.7209527784585954\n",
      "3600 completed. Loss: 3.26745285323821\n",
      "3800 completed. Loss: 2.9162539075221865\n",
      "4000 completed. Loss: 3.384797044927254\n",
      "4200 completed. Loss: 2.631106699826196\n",
      "4400 completed. Loss: 3.2801063408108893\n",
      "4600 completed. Loss: 3.4241884856252\n",
      "4800 completed. Loss: 3.174976520901546\n",
      "5000 completed. Loss: 2.905588848820189\n",
      "5200 completed. Loss: 2.631362790092826\n",
      "5400 completed. Loss: 3.0414438166841866\n",
      "5600 completed. Loss: 2.5714368467312307\n",
      "5800 completed. Loss: 3.0129231872828677\n",
      "6000 completed. Loss: 2.5012879362422975\n",
      "6200 completed. Loss: 2.789224788011052\n",
      "6400 completed. Loss: 2.905368438065052\n",
      "6600 completed. Loss: 2.7841053464729337\n",
      "6800 completed. Loss: 2.512964370455593\n",
      "7000 completed. Loss: 2.4668399206083267\n",
      "7200 completed. Loss: 3.1773611748032273\n",
      "7400 completed. Loss: 2.3873392389551737\n",
      "7600 completed. Loss: 2.7501768895611165\n",
      "7800 completed. Loss: 3.284172685472295\n",
      "8000 completed. Loss: 2.9053148161806166\n",
      "8200 completed. Loss: 4.276489799292758\n",
      "8400 completed. Loss: 2.84948100496782\n",
      "8600 completed. Loss: 2.6227371123549528\n",
      "8800 completed. Loss: 2.976176285208203\n",
      "9000 completed. Loss: 3.493412258606404\n",
      "9200 completed. Loss: 3.0932427341863513\n",
      "200 completed. Loss: 3.4777105228230356\n",
      "400 completed. Loss: 3.2307875026017427\n",
      "600 completed. Loss: 3.2073081650212405\n",
      "800 completed. Loss: 3.2896724229864778\n",
      "1000 completed. Loss: 3.3045937876868994\n",
      "1200 completed. Loss: 3.157234490038827\n",
      "1400 completed. Loss: 3.1515093100070954\n",
      "1600 completed. Loss: 2.734590097554028\n",
      "1800 completed. Loss: 3.234717983826995\n",
      "2000 completed. Loss: 3.139877491183579\n",
      "2200 completed. Loss: 3.0858387616474645\n",
      "2400 completed. Loss: 2.584911464001052\n",
      "2600 completed. Loss: 3.2300721692107617\n",
      "2800 completed. Loss: 2.4783288227254525\n",
      "3000 completed. Loss: 3.28056534815114\n",
      "3200 completed. Loss: 2.9507000786275603\n",
      "3400 completed. Loss: 2.729149605957791\n",
      "3600 completed. Loss: 3.212358401031233\n",
      "3800 completed. Loss: 3.2324085128633304\n",
      "4000 completed. Loss: 3.4340513147599996\n",
      "4200 completed. Loss: 3.0310574430879207\n",
      "4400 completed. Loss: 3.2861070325039328\n",
      "4600 completed. Loss: 3.3363267573015762\n",
      "4800 completed. Loss: 3.121739254742861\n",
      "5000 completed. Loss: 2.918405354921706\n",
      "5200 completed. Loss: 2.711461696487386\n",
      "5400 completed. Loss: 3.084984961859882\n",
      "5600 completed. Loss: 2.5533436351735146\n",
      "5800 completed. Loss: 3.19885984973982\n",
      "6000 completed. Loss: 2.522346035828814\n",
      "6200 completed. Loss: 3.0059607693133876\n",
      "6400 completed. Loss: 3.2438696422660724\n",
      "6600 completed. Loss: 2.5039506969274954\n",
      "6800 completed. Loss: 2.563759810300544\n",
      "7000 completed. Loss: 2.5493926804140212\n",
      "7200 completed. Loss: 2.9569766547251493\n",
      "7400 completed. Loss: 2.345782239194959\n",
      "7600 completed. Loss: 2.9001824889332055\n",
      "7800 completed. Loss: 2.88862513856031\n",
      "8000 completed. Loss: 3.2543885791301728\n",
      "8200 completed. Loss: 3.853577183368616\n",
      "8400 completed. Loss: 2.7726660571992396\n",
      "8600 completed. Loss: 2.737149920454249\n",
      "8800 completed. Loss: 2.949900642815046\n",
      "9000 completed. Loss: 4.019611719870008\n",
      "9200 completed. Loss: 3.236939139664173\n",
      "200 completed. Loss: 3.334209244828671\n",
      "400 completed. Loss: 3.573108607167378\n",
      "600 completed. Loss: 3.5089306173939256\n",
      "800 completed. Loss: 3.218598686028272\n",
      "1000 completed. Loss: 3.1886544013023377\n",
      "1200 completed. Loss: 3.014178835293278\n",
      "1400 completed. Loss: 2.817262051384896\n",
      "1600 completed. Loss: 2.841042467150837\n",
      "1800 completed. Loss: 3.238023661505431\n",
      "2000 completed. Loss: 3.1979600075259804\n",
      "2200 completed. Loss: 3.1711100871581586\n",
      "2400 completed. Loss: 2.5781529911234973\n",
      "2600 completed. Loss: 2.9845010410808026\n",
      "2800 completed. Loss: 2.4206882527284326\n",
      "3000 completed. Loss: 3.3180494957137854\n",
      "3200 completed. Loss: 2.8155743611603974\n",
      "3400 completed. Loss: 2.9674893532996065\n",
      "3600 completed. Loss: 3.495152810551226\n",
      "3800 completed. Loss: 3.333383471146226\n",
      "4000 completed. Loss: 3.2825372008886187\n",
      "4200 completed. Loss: 2.872800809396431\n",
      "4400 completed. Loss: 3.360520816538483\n",
      "4600 completed. Loss: 3.364057320674183\n",
      "4800 completed. Loss: 3.362051621139981\n",
      "5000 completed. Loss: 3.037477884674445\n",
      "5200 completed. Loss: 2.643846661839634\n",
      "5400 completed. Loss: 3.0879034621827306\n",
      "5600 completed. Loss: 2.512075510583818\n",
      "5800 completed. Loss: 3.0166927122324707\n",
      "6000 completed. Loss: 2.5022103366069497\n",
      "6200 completed. Loss: 2.6395510372135322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 completed. Loss: 3.049027082333341\n",
      "6600 completed. Loss: 2.560356286484748\n",
      "6800 completed. Loss: 2.488363629844971\n",
      "7000 completed. Loss: 2.5526656199339777\n",
      "7200 completed. Loss: 2.8815088739525527\n",
      "7400 completed. Loss: 2.415325789162889\n",
      "7600 completed. Loss: 2.5985561630595475\n",
      "7800 completed. Loss: 2.933544760989025\n",
      "8000 completed. Loss: 3.1472911251708866\n",
      "8200 completed. Loss: 3.913384941574186\n",
      "8400 completed. Loss: 2.78872540235403\n",
      "8600 completed. Loss: 2.8183903222158553\n",
      "8800 completed. Loss: 2.7246792370639743\n",
      "9000 completed. Loss: 3.8451999539881943\n",
      "9200 completed. Loss: 3.0183394578658045\n",
      "200 completed. Loss: 3.2013860921841113\n",
      "400 completed. Loss: 3.278233437249437\n",
      "600 completed. Loss: 3.342189224790782\n",
      "800 completed. Loss: 2.9906964910123497\n",
      "1000 completed. Loss: 3.18595908281859\n",
      "1200 completed. Loss: 3.1310536148236134\n",
      "1400 completed. Loss: 2.9744078811677173\n",
      "1600 completed. Loss: 3.042497980259359\n",
      "1800 completed. Loss: 3.3311121481470765\n",
      "2000 completed. Loss: 2.8956039778189733\n",
      "2200 completed. Loss: 3.034345054803416\n",
      "2400 completed. Loss: 2.66199943064712\n",
      "2600 completed. Loss: 3.1926015387941153\n",
      "2800 completed. Loss: 2.5377761557884515\n",
      "3000 completed. Loss: 3.095409311139956\n",
      "3200 completed. Loss: 2.996648055072874\n",
      "3400 completed. Loss: 3.1900121886050328\n",
      "3600 completed. Loss: 3.4945022244751454\n",
      "3800 completed. Loss: 2.826803146234015\n",
      "4000 completed. Loss: 3.33439734114334\n",
      "4200 completed. Loss: 2.5193320753239097\n",
      "4400 completed. Loss: 3.1783296638447793\n",
      "4600 completed. Loss: 3.134800323890522\n",
      "4800 completed. Loss: 3.1064247120171786\n",
      "5000 completed. Loss: 2.9158414776623247\n",
      "5200 completed. Loss: 2.593427888872102\n",
      "5400 completed. Loss: 3.0909964163880796\n",
      "5600 completed. Loss: 2.6122209596354513\n",
      "5800 completed. Loss: 2.8690606161393224\n",
      "6000 completed. Loss: 2.5890744590386747\n",
      "6200 completed. Loss: 2.9510903570707887\n",
      "6400 completed. Loss: 2.8637290057353675\n",
      "6600 completed. Loss: 2.714071965608746\n",
      "6800 completed. Loss: 2.3229051074478777\n",
      "7000 completed. Loss: 2.6336222285404802\n",
      "7200 completed. Loss: 2.902907211938873\n",
      "7400 completed. Loss: 2.360970575362444\n",
      "7600 completed. Loss: 2.7778247978724537\n",
      "7800 completed. Loss: 3.0404264209605754\n",
      "8000 completed. Loss: 3.2659476583823563\n",
      "8200 completed. Loss: 4.106011675326154\n",
      "8400 completed. Loss: 3.147293226858601\n",
      "8600 completed. Loss: 2.97328579149209\n",
      "8800 completed. Loss: 2.910993079803884\n",
      "9000 completed. Loss: 3.897465156484395\n",
      "9200 completed. Loss: 3.099799587582238\n",
      "200 completed. Loss: 3.515245218798518\n",
      "400 completed. Loss: 3.097533312384039\n",
      "600 completed. Loss: 3.2281990095088258\n",
      "800 completed. Loss: 3.0220148259960116\n",
      "1000 completed. Loss: 3.41441133921966\n",
      "1200 completed. Loss: 2.9712022317759694\n",
      "1400 completed. Loss: 3.104892107024789\n",
      "1600 completed. Loss: 2.940685935094953\n",
      "1800 completed. Loss: 3.2065555014368146\n",
      "2000 completed. Loss: 3.371164756438229\n",
      "2200 completed. Loss: 3.065461597777903\n",
      "2400 completed. Loss: 2.789941907785833\n",
      "2600 completed. Loss: 3.0404247565777043\n",
      "2800 completed. Loss: 2.5254903318826107\n",
      "3000 completed. Loss: 3.3485788365267215\n",
      "3200 completed. Loss: 2.7250175813166426\n",
      "3400 completed. Loss: 3.095961429812014\n",
      "3600 completed. Loss: 3.2260545331425963\n",
      "3800 completed. Loss: 3.0457278256863356\n",
      "4000 completed. Loss: 3.261544745452702\n",
      "4200 completed. Loss: 2.642567277145572\n",
      "4400 completed. Loss: 3.2012910440051927\n",
      "4600 completed. Loss: 3.193987226560712\n",
      "4800 completed. Loss: 3.2693009760603307\n",
      "5000 completed. Loss: 2.9738947426341475\n",
      "5200 completed. Loss: 2.6139312910102306\n",
      "5400 completed. Loss: 2.9821527468040587\n",
      "5600 completed. Loss: 2.6058596617518925\n",
      "5800 completed. Loss: 2.9051564515940846\n",
      "6000 completed. Loss: 2.585709374770522\n",
      "6200 completed. Loss: 2.684969678884372\n",
      "6400 completed. Loss: 2.926557978638448\n",
      "6600 completed. Loss: 2.6712871843390165\n",
      "6800 completed. Loss: 2.6702383362688122\n",
      "7000 completed. Loss: 2.759980733147822\n",
      "7200 completed. Loss: 3.20601387957111\n",
      "7400 completed. Loss: 2.4240681253001095\n",
      "7600 completed. Loss: 2.9543637094786392\n",
      "7800 completed. Loss: 3.200408957004547\n",
      "8000 completed. Loss: 2.84142610614188\n",
      "8200 completed. Loss: 4.040868901023641\n",
      "8400 completed. Loss: 2.8276058772346007\n",
      "8600 completed. Loss: 3.0668205575295726\n",
      "8800 completed. Loss: 2.8233024486061185\n",
      "9000 completed. Loss: 4.304740296173841\n",
      "9200 completed. Loss: 3.1412494772672654\n",
      "200 completed. Loss: 3.1614256084524097\n",
      "400 completed. Loss: 3.077093589119613\n",
      "600 completed. Loss: 3.270854121558368\n",
      "800 completed. Loss: 3.096252591870725\n",
      "1000 completed. Loss: 3.255072186663747\n",
      "1200 completed. Loss: 3.0030788010172547\n",
      "1400 completed. Loss: 3.220825133784674\n",
      "1600 completed. Loss: 2.7106276190583594\n",
      "1800 completed. Loss: 3.095338363330811\n",
      "2000 completed. Loss: 3.0320166178408545\n",
      "2200 completed. Loss: 3.1343856483511625\n",
      "2400 completed. Loss: 2.7151767147704957\n",
      "2600 completed. Loss: 3.023959792846581\n",
      "2800 completed. Loss: 2.5602109201811256\n",
      "3000 completed. Loss: 3.524477378856391\n",
      "3200 completed. Loss: 2.6719973302283324\n",
      "3400 completed. Loss: 2.915571448688861\n",
      "3600 completed. Loss: 3.202891264166683\n",
      "3800 completed. Loss: 3.329428356923163\n",
      "4000 completed. Loss: 3.2831370286876336\n",
      "4200 completed. Loss: 2.987253846246749\n",
      "4400 completed. Loss: 3.458371474575251\n",
      "4600 completed. Loss: 3.4220772179798224\n",
      "4800 completed. Loss: 3.2293870160472578\n",
      "5000 completed. Loss: 3.2285752460639925\n",
      "5200 completed. Loss: 2.7723983318451793\n",
      "5400 completed. Loss: 3.0630577441491185\n",
      "5600 completed. Loss: 2.707946419576183\n",
      "5800 completed. Loss: 2.862613355475478\n",
      "6000 completed. Loss: 2.3838191258115695\n",
      "6200 completed. Loss: 2.747686854200438\n",
      "6400 completed. Loss: 2.987567242535297\n",
      "6600 completed. Loss: 2.741251073293388\n",
      "6800 completed. Loss: 2.439444841891527\n",
      "7000 completed. Loss: 2.6330422170832755\n",
      "7200 completed. Loss: 3.043751675798558\n",
      "7400 completed. Loss: 2.3735025413800033\n",
      "7600 completed. Loss: 2.9360384350456297\n",
      "7800 completed. Loss: 2.7665457117836922\n",
      "8000 completed. Loss: 3.009519609240815\n",
      "8200 completed. Loss: 4.290279624173418\n",
      "8400 completed. Loss: 2.9477802271116524\n",
      "8600 completed. Loss: 3.0996286937221886\n",
      "8800 completed. Loss: 2.7723650036472827\n",
      "9000 completed. Loss: 4.127023273287341\n",
      "9200 completed. Loss: 3.2485326017905027\n",
      "200 completed. Loss: 3.1316727216355504\n",
      "400 completed. Loss: 3.1146182361245156\n",
      "600 completed. Loss: 3.2756436491571366\n",
      "800 completed. Loss: 3.070414263261482\n",
      "1000 completed. Loss: 3.235559089547023\n",
      "1200 completed. Loss: 3.259923313520849\n",
      "1400 completed. Loss: 3.068860942684114\n",
      "1600 completed. Loss: 2.6862226938456297\n",
      "1800 completed. Loss: 3.5702673116605728\n",
      "2000 completed. Loss: 3.0568550868635067\n",
      "2200 completed. Loss: 3.1790087555907665\n",
      "2400 completed. Loss: 2.7072665765415875\n",
      "2600 completed. Loss: 3.1216001557884736\n",
      "2800 completed. Loss: 2.5480166031233966\n",
      "3000 completed. Loss: 3.591862973663956\n",
      "3200 completed. Loss: 2.6322261521406474\n",
      "3400 completed. Loss: 3.0840353646455334\n",
      "3600 completed. Loss: 3.4716874852078035\n",
      "3800 completed. Loss: 2.9606164738163354\n",
      "4000 completed. Loss: 3.3340297451941296\n",
      "4200 completed. Loss: 2.847848353902809\n",
      "4400 completed. Loss: 3.256665451861918\n",
      "4600 completed. Loss: 3.3629562453832476\n",
      "4800 completed. Loss: 3.26004995374009\n",
      "5000 completed. Loss: 2.851243709586561\n",
      "5200 completed. Loss: 2.823914482628461\n",
      "5400 completed. Loss: 3.1174331784434615\n",
      "5600 completed. Loss: 2.6394333734922113\n",
      "5800 completed. Loss: 2.907690565790981\n",
      "6000 completed. Loss: 2.5453219442628323\n",
      "6200 completed. Loss: 2.839085736470297\n",
      "6400 completed. Loss: 2.9096356317028405\n",
      "6600 completed. Loss: 2.572227420983836\n",
      "6800 completed. Loss: 2.36058274355717\n",
      "7000 completed. Loss: 2.576448623640463\n",
      "7200 completed. Loss: 2.9757413961179555\n",
      "7400 completed. Loss: 2.292225384423509\n",
      "7600 completed. Loss: 2.5508694885857404\n",
      "7800 completed. Loss: 3.2711656997120007\n",
      "8000 completed. Loss: 3.269771594554186\n",
      "8200 completed. Loss: 3.985978389759548\n",
      "8400 completed. Loss: 3.0512901810533366\n",
      "8600 completed. Loss: 2.955907187703997\n",
      "8800 completed. Loss: 3.1358794177230447\n",
      "9000 completed. Loss: 3.965304397325963\n",
      "9200 completed. Loss: 3.183544023381546\n",
      "200 completed. Loss: 2.9890205861628054\n",
      "400 completed. Loss: 3.286798271620646\n",
      "600 completed. Loss: 3.466467810543254\n",
      "800 completed. Loss: 3.134062188756652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 completed. Loss: 3.406823978200555\n",
      "1200 completed. Loss: 3.0523957794439047\n",
      "1400 completed. Loss: 3.149519882053137\n",
      "1600 completed. Loss: 2.7391467132233083\n",
      "1800 completed. Loss: 3.32707495033741\n",
      "2000 completed. Loss: 3.179999720863998\n",
      "2200 completed. Loss: 3.0982248350046575\n",
      "2400 completed. Loss: 2.693012358514825\n",
      "2600 completed. Loss: 3.1873985865339636\n",
      "2800 completed. Loss: 2.4892952839192004\n",
      "3000 completed. Loss: 3.401254589743912\n",
      "3200 completed. Loss: 2.74456453259103\n",
      "3400 completed. Loss: 2.899852893752977\n",
      "3600 completed. Loss: 3.175195469716564\n",
      "3800 completed. Loss: 3.0609737662458794\n",
      "4000 completed. Loss: 3.376312628798187\n",
      "4200 completed. Loss: 2.8731120937690138\n",
      "4400 completed. Loss: 3.4748709937464444\n",
      "4600 completed. Loss: 3.290214088307694\n",
      "4800 completed. Loss: 2.9411040316615256\n",
      "5000 completed. Loss: 2.9188975076377393\n",
      "5200 completed. Loss: 2.521078279954381\n",
      "5400 completed. Loss: 2.900116869844496\n",
      "5600 completed. Loss: 2.6405761498585343\n",
      "5800 completed. Loss: 2.7655553652811795\n",
      "6000 completed. Loss: 2.5878206777293236\n",
      "6200 completed. Loss: 2.644799474263564\n",
      "6400 completed. Loss: 3.206671901224181\n",
      "6600 completed. Loss: 2.5037485519237817\n",
      "6800 completed. Loss: 2.2567749807890505\n",
      "7000 completed. Loss: 2.5053498230315743\n",
      "7200 completed. Loss: 2.945665545044467\n",
      "7400 completed. Loss: 2.3373809470279956\n",
      "7600 completed. Loss: 2.8103055938379837\n",
      "7800 completed. Loss: 3.0083511385880413\n",
      "8000 completed. Loss: 3.050056640552357\n",
      "8200 completed. Loss: 4.0918500252626835\n",
      "8400 completed. Loss: 3.0378578553535043\n",
      "8600 completed. Loss: 2.8569256103225054\n",
      "8800 completed. Loss: 2.972267139554024\n",
      "9000 completed. Loss: 3.6042549679381772\n",
      "9200 completed. Loss: 3.215885268119164\n",
      "200 completed. Loss: 3.0736306415032595\n",
      "400 completed. Loss: 3.251377281434834\n",
      "600 completed. Loss: 3.2770640587154776\n",
      "800 completed. Loss: 3.0007809149846434\n",
      "1000 completed. Loss: 3.333609382901341\n",
      "1200 completed. Loss: 3.056145984381437\n",
      "1400 completed. Loss: 3.0081230729212987\n",
      "1600 completed. Loss: 2.9175406877603383\n",
      "1800 completed. Loss: 2.9821287824283353\n",
      "2000 completed. Loss: 3.0373549253772945\n",
      "2200 completed. Loss: 3.062625653506257\n",
      "2400 completed. Loss: 2.985661067906767\n",
      "2600 completed. Loss: 3.484202970713377\n",
      "2800 completed. Loss: 2.529419235670939\n",
      "3000 completed. Loss: 3.474639823921025\n",
      "3200 completed. Loss: 2.9121528461482376\n",
      "3400 completed. Loss: 2.99956680345349\n",
      "3600 completed. Loss: 2.973023056052625\n",
      "3800 completed. Loss: 3.575427487762645\n",
      "4000 completed. Loss: 3.2842634957283736\n",
      "4200 completed. Loss: 2.7721715827472506\n",
      "4400 completed. Loss: 3.2989087394438683\n",
      "4600 completed. Loss: 3.611020357850939\n",
      "4800 completed. Loss: 2.9258099637087436\n",
      "5000 completed. Loss: 3.0372705360129477\n",
      "5200 completed. Loss: 2.6302463509701193\n",
      "5400 completed. Loss: 3.0023658415023236\n",
      "5600 completed. Loss: 2.585621290076524\n",
      "5800 completed. Loss: 2.902962672030553\n",
      "6000 completed. Loss: 2.461514326131437\n",
      "6200 completed. Loss: 2.7864069202775137\n",
      "6400 completed. Loss: 3.0182220501452686\n",
      "6600 completed. Loss: 2.5317498164158314\n",
      "6800 completed. Loss: 2.564671113609802\n",
      "7000 completed. Loss: 2.4838363787904383\n",
      "7200 completed. Loss: 2.7295021421671843\n",
      "7400 completed. Loss: 2.3469118367834017\n",
      "7600 completed. Loss: 2.8271338904369623\n",
      "7800 completed. Loss: 3.091180301485583\n",
      "8000 completed. Loss: 2.9821424009581095\n",
      "8200 completed. Loss: 3.6198364890925587\n",
      "8400 completed. Loss: 2.888599963122979\n",
      "8600 completed. Loss: 2.8714245254267006\n",
      "8800 completed. Loss: 3.1034203096525745\n",
      "9000 completed. Loss: 4.140325682777911\n",
      "9200 completed. Loss: 3.376651604603976\n",
      "200 completed. Loss: 3.1541312176920475\n",
      "400 completed. Loss: 3.0084894070588053\n",
      "600 completed. Loss: 3.1072396741597914\n",
      "800 completed. Loss: 2.8593562693335115\n",
      "1000 completed. Loss: 3.4604412061721086\n",
      "1200 completed. Loss: 2.975055450173095\n",
      "1400 completed. Loss: 3.026511868229136\n",
      "1600 completed. Loss: 2.8965206372458487\n",
      "1800 completed. Loss: 3.085766323665157\n",
      "2000 completed. Loss: 3.0916869930783286\n",
      "2200 completed. Loss: 2.846191426422447\n",
      "2400 completed. Loss: 2.727592844958417\n",
      "2600 completed. Loss: 2.9299193474650385\n",
      "2800 completed. Loss: 2.3296314137848095\n",
      "3000 completed. Loss: 3.489748458135873\n",
      "3200 completed. Loss: 2.8075539713725446\n",
      "3400 completed. Loss: 2.946426648935303\n",
      "3600 completed. Loss: 3.370803189417347\n",
      "3800 completed. Loss: 2.9576437915256246\n",
      "4000 completed. Loss: 3.7895891323219986\n",
      "4200 completed. Loss: 2.927960324883461\n",
      "4400 completed. Loss: 3.2177206927724185\n",
      "4600 completed. Loss: 3.3129826490627603\n",
      "4800 completed. Loss: 3.18367064954713\n",
      "5000 completed. Loss: 2.8595136591419577\n",
      "5200 completed. Loss: 2.786478433962911\n",
      "5400 completed. Loss: 3.386104578971863\n",
      "5600 completed. Loss: 2.5753349144151434\n",
      "5800 completed. Loss: 2.7984285331796857\n",
      "6000 completed. Loss: 2.5720743510499595\n",
      "6200 completed. Loss: 2.7554204929596744\n",
      "6400 completed. Loss: 2.903565570358187\n",
      "6600 completed. Loss: 2.5140806606831028\n",
      "6800 completed. Loss: 2.4718390915635973\n",
      "7000 completed. Loss: 2.517737367339432\n",
      "7200 completed. Loss: 3.045399388410151\n",
      "7400 completed. Loss: 2.456791908768937\n",
      "7600 completed. Loss: 2.643623685380444\n",
      "7800 completed. Loss: 3.3155741746304557\n",
      "8000 completed. Loss: 3.473707589339465\n",
      "8200 completed. Loss: 3.7399179137311878\n",
      "8400 completed. Loss: 2.9736149205639957\n",
      "8600 completed. Loss: 2.831397178855259\n",
      "8800 completed. Loss: 3.0966191887948664\n",
      "9000 completed. Loss: 3.8818952428875493\n",
      "9200 completed. Loss: 3.365450442880392\n",
      "200 completed. Loss: 3.021358955912292\n",
      "400 completed. Loss: 2.977851706966758\n",
      "600 completed. Loss: 3.2206198989227413\n",
      "800 completed. Loss: 3.0718734230287374\n",
      "1000 completed. Loss: 3.5751915304269644\n",
      "1200 completed. Loss: 3.1019963692501187\n",
      "1400 completed. Loss: 2.9177233569696543\n",
      "1600 completed. Loss: 2.7937083175219595\n",
      "1800 completed. Loss: 3.286343136942014\n",
      "2000 completed. Loss: 2.9387473550532013\n",
      "2200 completed. Loss: 3.325103607270867\n",
      "2400 completed. Loss: 2.541159392055124\n",
      "2600 completed. Loss: 3.1395145929977297\n",
      "2800 completed. Loss: 2.579370879838243\n",
      "3000 completed. Loss: 3.5124179630633443\n",
      "3200 completed. Loss: 2.901359309484251\n",
      "3400 completed. Loss: 3.0846908413711933\n",
      "3600 completed. Loss: 3.2639352476643397\n",
      "3800 completed. Loss: 2.9947616524156184\n",
      "4000 completed. Loss: 3.428024958856404\n",
      "4200 completed. Loss: 2.837648604279384\n",
      "4400 completed. Loss: 3.1620479992218318\n",
      "4600 completed. Loss: 3.512893311660737\n",
      "4800 completed. Loss: 3.0917882309993727\n",
      "5000 completed. Loss: 3.1753155960142614\n",
      "5200 completed. Loss: 2.6819689868413845\n",
      "5400 completed. Loss: 2.7685302741639317\n",
      "5600 completed. Loss: 2.4384948832634836\n",
      "5800 completed. Loss: 3.0278856916446237\n",
      "6000 completed. Loss: 2.530103322137147\n",
      "6200 completed. Loss: 2.716821803143248\n",
      "6400 completed. Loss: 3.2531432792381385\n",
      "6600 completed. Loss: 2.4147328138662854\n",
      "6800 completed. Loss: 2.286062674433924\n",
      "7000 completed. Loss: 2.727247320981696\n",
      "7200 completed. Loss: 3.031677998770028\n",
      "7400 completed. Loss: 2.2934760946594177\n",
      "7600 completed. Loss: 2.7858141003805215\n",
      "7800 completed. Loss: 3.130811615413986\n",
      "8000 completed. Loss: 3.3177705011563376\n",
      "8200 completed. Loss: 4.230069273114204\n",
      "8400 completed. Loss: 2.952955503955018\n",
      "8600 completed. Loss: 3.120702828490175\n",
      "8800 completed. Loss: 2.84794262252748\n",
      "9000 completed. Loss: 3.839587208693847\n",
      "9200 completed. Loss: 3.314481763568474\n",
      "200 completed. Loss: 3.226139140985906\n",
      "400 completed. Loss: 2.9918288856558504\n",
      "600 completed. Loss: 3.246546050067991\n",
      "800 completed. Loss: 2.815191036881879\n",
      "1000 completed. Loss: 3.3041860764380546\n",
      "1200 completed. Loss: 3.1849485724791884\n",
      "1400 completed. Loss: 3.0888902759365737\n",
      "1600 completed. Loss: 3.005586470160633\n",
      "1800 completed. Loss: 2.895614071333548\n",
      "2000 completed. Loss: 3.015353391156532\n",
      "2200 completed. Loss: 3.0261581940855833\n",
      "2400 completed. Loss: 2.7719133652932944\n",
      "2600 completed. Loss: 3.088564751157537\n",
      "2800 completed. Loss: 2.5186249010683968\n",
      "3000 completed. Loss: 3.173397891372442\n",
      "3200 completed. Loss: 2.9207237140275537\n",
      "3400 completed. Loss: 2.91134029840352\n",
      "3600 completed. Loss: 3.068995492486283\n",
      "3800 completed. Loss: 3.1686610623449085\n",
      "4000 completed. Loss: 3.4395569973578675\n",
      "4200 completed. Loss: 2.8725605520792303\n",
      "4400 completed. Loss: 3.325143663119525\n",
      "4600 completed. Loss: 3.414522735718638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 completed. Loss: 3.439129614951089\n",
      "5000 completed. Loss: 2.926627692785114\n",
      "5200 completed. Loss: 2.740609466098249\n",
      "5400 completed. Loss: 3.318321754913777\n",
      "5600 completed. Loss: 2.4722719004936518\n",
      "5800 completed. Loss: 2.7567923275753854\n",
      "6000 completed. Loss: 2.3434910662565382\n",
      "6200 completed. Loss: 2.8970861725509165\n",
      "6400 completed. Loss: 3.2047167234309017\n",
      "6600 completed. Loss: 2.5280081715807317\n",
      "6800 completed. Loss: 2.4919869686849414\n",
      "7000 completed. Loss: 2.5860454128868877\n",
      "7200 completed. Loss: 2.879932537674904\n",
      "7400 completed. Loss: 2.3815530429640783\n",
      "7600 completed. Loss: 2.606496999580413\n",
      "7800 completed. Loss: 3.2508096377551556\n",
      "8000 completed. Loss: 2.997359980074689\n",
      "8200 completed. Loss: 3.789708226537332\n",
      "8400 completed. Loss: 3.2835560169350355\n",
      "8600 completed. Loss: 2.6338245315011592\n",
      "8800 completed. Loss: 3.009725490855053\n",
      "9000 completed. Loss: 4.275090329591185\n",
      "9200 completed. Loss: 3.380465069944039\n",
      "200 completed. Loss: 3.2260170053783805\n",
      "400 completed. Loss: 3.0694400830566884\n",
      "600 completed. Loss: 3.190299641098827\n",
      "800 completed. Loss: 2.9355678348336367\n",
      "1000 completed. Loss: 3.3945406292541884\n",
      "1200 completed. Loss: 2.9658198536373677\n",
      "1400 completed. Loss: 2.9020041411044075\n",
      "1600 completed. Loss: 2.841454535899684\n",
      "1800 completed. Loss: 3.218137631714344\n",
      "2000 completed. Loss: 3.0537549758981912\n",
      "2200 completed. Loss: 3.0741498977690935\n",
      "2400 completed. Loss: 2.8183835926279426\n",
      "2600 completed. Loss: 3.097163351289928\n",
      "2800 completed. Loss: 2.5826966158067806\n",
      "3000 completed. Loss: 3.2661028676968997\n",
      "3200 completed. Loss: 2.819860088676214\n",
      "3400 completed. Loss: 2.957549224551767\n",
      "3600 completed. Loss: 3.287187145994976\n",
      "3800 completed. Loss: 3.2514631576277315\n",
      "4000 completed. Loss: 3.47831420394592\n",
      "4200 completed. Loss: 2.7558518154453484\n",
      "4400 completed. Loss: 3.2378695370396597\n",
      "4600 completed. Loss: 3.488175869309343\n",
      "4800 completed. Loss: 3.076171187516302\n",
      "5000 completed. Loss: 2.9579357156762853\n",
      "5200 completed. Loss: 2.6889674158766868\n",
      "5400 completed. Loss: 2.9828191354032607\n",
      "5600 completed. Loss: 2.5226685400353746\n",
      "5800 completed. Loss: 2.8931925172079356\n",
      "6000 completed. Loss: 2.4992943016439675\n",
      "6200 completed. Loss: 2.8111043904069812\n",
      "6400 completed. Loss: 3.1871461781766266\n",
      "6600 completed. Loss: 2.5160848229797557\n",
      "6800 completed. Loss: 2.246933342139237\n",
      "7000 completed. Loss: 2.741912426974159\n",
      "7200 completed. Loss: 2.9733451868221166\n",
      "7400 completed. Loss: 2.311370262429118\n",
      "7600 completed. Loss: 2.8590671340655534\n",
      "7800 completed. Loss: 2.9410434067435562\n",
      "8000 completed. Loss: 3.231552171818912\n",
      "8200 completed. Loss: 3.5961140424292535\n",
      "8400 completed. Loss: 2.788424454797059\n",
      "8600 completed. Loss: 2.6709703303128483\n",
      "8800 completed. Loss: 3.0863719998579473\n",
      "9000 completed. Loss: 3.999805597937666\n",
      "9200 completed. Loss: 3.2809117366047578\n",
      "200 completed. Loss: 3.043326750509441\n",
      "400 completed. Loss: 3.2012126342579723\n",
      "600 completed. Loss: 3.3359412795770913\n",
      "800 completed. Loss: 3.0716962531674654\n",
      "1000 completed. Loss: 3.3074798073805867\n",
      "1200 completed. Loss: 3.0958895218931137\n",
      "1400 completed. Loss: 2.7915577657613904\n",
      "1600 completed. Loss: 2.6589157160837202\n",
      "1800 completed. Loss: 3.279164620898664\n",
      "2000 completed. Loss: 3.083119226563722\n",
      "2200 completed. Loss: 3.233654339099303\n",
      "2400 completed. Loss: 2.505145366974175\n",
      "2600 completed. Loss: 3.013084677057341\n",
      "2800 completed. Loss: 2.4427320996578783\n",
      "3000 completed. Loss: 3.4423265416920183\n",
      "3200 completed. Loss: 2.7985748692601917\n",
      "3400 completed. Loss: 3.012462736191228\n",
      "3600 completed. Loss: 3.2813965958170592\n",
      "3800 completed. Loss: 3.4150056027527897\n",
      "4000 completed. Loss: 3.3707440971583127\n",
      "4200 completed. Loss: 2.6191818484663965\n",
      "4400 completed. Loss: 3.3686066816793754\n",
      "4600 completed. Loss: 3.527221914427355\n",
      "4800 completed. Loss: 3.1129371819924563\n",
      "5000 completed. Loss: 3.1002464750409127\n",
      "5200 completed. Loss: 2.677849968839437\n",
      "5400 completed. Loss: 2.981292713363655\n",
      "5600 completed. Loss: 2.7397908328380436\n",
      "5800 completed. Loss: 2.825622377274558\n",
      "6000 completed. Loss: 2.587065313067287\n",
      "6200 completed. Loss: 2.489344344139099\n",
      "6400 completed. Loss: 3.1367238893173637\n",
      "6600 completed. Loss: 2.4292762314388527\n",
      "6800 completed. Loss: 2.4021249189786613\n",
      "7000 completed. Loss: 2.624627209501341\n",
      "7200 completed. Loss: 3.098051658105105\n",
      "7400 completed. Loss: 2.438579885195941\n",
      "7600 completed. Loss: 2.843802895117551\n",
      "7800 completed. Loss: 3.1171240901388226\n",
      "8000 completed. Loss: 3.2551839581038804\n",
      "8200 completed. Loss: 3.5891839822568\n",
      "8400 completed. Loss: 3.0238562414748595\n",
      "8600 completed. Loss: 3.0371115384669976\n",
      "8800 completed. Loss: 3.1515311012417078\n",
      "9000 completed. Loss: 4.221183353965171\n",
      "9200 completed. Loss: 3.185296568875201\n",
      "200 completed. Loss: 3.3270663972850887\n",
      "400 completed. Loss: 3.291552470861934\n",
      "600 completed. Loss: 3.247974764816463\n",
      "800 completed. Loss: 2.9695294933672995\n",
      "1000 completed. Loss: 3.374778844676912\n",
      "1200 completed. Loss: 2.890409553796053\n",
      "1400 completed. Loss: 2.8522793659195305\n",
      "1600 completed. Loss: 2.784052339978516\n",
      "1800 completed. Loss: 3.240378579106182\n",
      "2000 completed. Loss: 3.0095173220685685\n",
      "2200 completed. Loss: 2.9449138438515363\n",
      "2400 completed. Loss: 2.621962524927221\n",
      "2600 completed. Loss: 3.1588557204790413\n",
      "2800 completed. Loss: 2.466186077874154\n",
      "3000 completed. Loss: 3.4800183705240486\n",
      "3200 completed. Loss: 2.6327264130394905\n",
      "3400 completed. Loss: 2.8756685634190218\n",
      "3600 completed. Loss: 3.2619335533026605\n",
      "3800 completed. Loss: 2.9213350666174667\n",
      "4000 completed. Loss: 3.2734082741476596\n",
      "4200 completed. Loss: 2.715672894534655\n",
      "4400 completed. Loss: 3.1917357839643956\n",
      "4600 completed. Loss: 3.4682854858413337\n",
      "4800 completed. Loss: 3.102700647972524\n",
      "5000 completed. Loss: 2.949285711073317\n",
      "5200 completed. Loss: 2.7854933182150123\n",
      "5400 completed. Loss: 3.130436821305193\n",
      "5600 completed. Loss: 2.5160501322336497\n",
      "5800 completed. Loss: 2.8459595284890384\n",
      "6000 completed. Loss: 2.2912785769673065\n",
      "6200 completed. Loss: 2.7931695841532203\n",
      "6400 completed. Loss: 3.044354076678865\n",
      "6600 completed. Loss: 2.4897216888237743\n",
      "6800 completed. Loss: 2.4135992548801006\n",
      "7000 completed. Loss: 2.4098068887367843\n",
      "7200 completed. Loss: 2.8901538122165946\n",
      "7400 completed. Loss: 2.247934259483591\n",
      "7600 completed. Loss: 2.876925205690786\n",
      "7800 completed. Loss: 2.7907213192246854\n",
      "8000 completed. Loss: 3.0209402521606536\n",
      "8200 completed. Loss: 4.442746197916567\n",
      "8400 completed. Loss: 3.0309438526351005\n",
      "8600 completed. Loss: 2.6792238899087533\n",
      "8800 completed. Loss: 3.0249349174369127\n",
      "9000 completed. Loss: 3.906262245317921\n",
      "9200 completed. Loss: 3.088186774235219\n"
     ]
    }
   ],
   "source": [
    "xs, ys = train(neural, optimizer, loss, n_scheduler, train_x, train_y, test_x, test_y, 30, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8114ae0c40>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs,[y.item() for y in ys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([917., 460., 295., 204., 134.,  78.,  59.,  44.,  37.,  21.,  17.,\n",
       "         17.,   7.,  11.,   5.,   5.,   7.,   3.,   5.,   1.,   2.,   1.,\n",
       "          2.,   1.]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24]),\n",
       " <BarContainer object of 24 artists>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3pSid13aHNU"
   },
   "outputs": [],
   "source": [
    "torch.save(neural.state_dict(), \"trained.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COMP562.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
